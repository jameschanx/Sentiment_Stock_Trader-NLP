{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#author: James Chan Â© 2018\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import st_utils as ut\n",
    "import datetime as dt\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "\n",
    "from dateutil import parser\n",
    "from datetime import timedelta, date\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize date range\n",
    "start_date = '2018-01-01'\n",
    "end_date = '2018-8-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'ok', 'totalResults': 1798, 'articles': []}\n",
      "total number of articles  1798\n",
      "downloading page:  1\n",
      "downloading page:  2\n",
      "downloading page:  3\n",
      "downloading page:  4\n",
      "downloading page:  5\n",
      "downloading page:  6\n",
      "downloading page:  7\n",
      "downloading page:  8\n",
      "downloading page:  9\n",
      "downloading page:  10\n",
      "downloading page:  11\n",
      "downloading page:  12\n",
      "downloading page:  13\n",
      "downloading page:  14\n",
      "downloading page:  15\n",
      "downloading page:  16\n",
      "downloading page:  17\n",
      "downloading page:  18\n",
      "download complete\n"
     ]
    }
   ],
   "source": [
    "# grab news.  nnly need to do this once\n",
    "keywords = ['tesla'] #these three stocks move largely base on news\n",
    "news_source = 'wsj.com, bloomberg.com, cnbc.com'\n",
    "df = ut.get_news(keywords, start_date, end_date, news_source)\n",
    "df.to_csv('news_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get Tesla's prices\n",
    "dates = pd.date_range(start_date, end_date)\n",
    "file = 'TSLA.csv'\n",
    "df_stock = ut.get_data(file, dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate return \n",
    "df_stock['Return'] = df_stock['Adj Close'].pct_change()\n",
    "df_stock.drop(df_stock.index[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_news = pd.read_csv('news_dataset.csv', index_col=0, encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# map published time to close date.  see figure.1\n",
    "def map_to_close_date(published_date):\n",
    "    dt = parser.parse(published_date[:-1]) #-1 to ignore the Z, which is GMT.\n",
    "    dt = dt - timedelta(hours=20) #shift back by 20 hrs.\n",
    "    return pd.Timestamp(year=dt.year, month=dt.month, day=dt.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map news to close date\n",
    "df_news['Published'] = df_news['Published'].apply(map_to_close_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine title and body into single text\n",
    "df_news['Text'] = df_news['Title'] + ' ' + df_news['Body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just keep published, and the combined text\n",
    "df_news = df_news[['Published','Text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge news and stock\n",
    "df_stock['Published'] = df_stock.index\n",
    "df_merged = pd.merge(df_news, df_stock, how='left', on='Published')\n",
    "df_merged = df_merged.dropna()\n",
    "df_merged.sort_values(by='Published')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stock['Published'] = df_stock.index\n",
    "df_merged = df_merged.dropna()\n",
    "df_merged.sort_values(by='Published')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_news(text):\n",
    "    if(type(text)==float):\n",
    "        return []\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    stmr = PorterStemmer()\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    text = (text.translate(translator))\n",
    "    text = \"\".join(c for c in text if ord(c)<128) #strip no n ascii characters\n",
    "    tokens = nltk.tokenize.word_tokenize(text)\n",
    "    t = []\n",
    "    minlen =  4\n",
    "    maxlen = 20 \n",
    "    for token in tokens:\n",
    "        if len(token) < minlen or len(token) > maxlen or token.isnumeric() or token in stopwords.words('english'):\n",
    "            pass\n",
    "        else:\n",
    "            token = lmtzr.lemmatize(token)\n",
    "            token = stmr.stem(token)\n",
    "            t.append(token)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['Text'] = df_merged['Text'].apply(tokenize_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct vocabulary and frequency.  frequency is not really needed, just nice to have for understanding the concept.\n",
    "vocab = {}\n",
    "frequency = {}\n",
    "ignore = ['bloomberg', 'journal']\n",
    "index = 0\n",
    "for title in df_merged['Text']:\n",
    "    for word in title:\n",
    "        if word in ignore:\n",
    "            continue\n",
    "        if word not in vocab:\n",
    "            vocab[word] = index\n",
    "            index += 1\n",
    "            frequency[word] = 1\n",
    "        else:\n",
    "            frequency[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize words frequency\n",
    "for i in sorted(frequency.items(), key=lambda x:x[1], reverse=True):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(vocab)\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_one_hot(text):\n",
    "    #return one hot vector of shape (vocab_len, 1)\n",
    "    array = np.zeros((vocab_len, 1))\n",
    "    for word in text:\n",
    "        if word in vocab:\n",
    "            index = vocab[word]\n",
    "            array[index] = 1\n",
    "    return array\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the exciting part. here we are going to create the training data!\n",
    "X = np.empty((vocab_len,0))\n",
    "for text in df_merged['Text']:\n",
    "    array = to_one_hot(text)\n",
    "    X = np.hstack((X,array))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Published</th>\n",
       "      <th>Text</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-04-02</td>\n",
       "      <td>[tesla, end, make, model, sedan, week, tesla, ...</td>\n",
       "      <td>252.479996</td>\n",
       "      <td>-0.051291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-07-23</td>\n",
       "      <td>[tesla, want, money, back, elon, musk, ask, do...</td>\n",
       "      <td>303.200012</td>\n",
       "      <td>-0.033102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-05-08</td>\n",
       "      <td>[florida, teenag, kill, tesla, crash, tesla, s...</td>\n",
       "      <td>301.970001</td>\n",
       "      <td>-0.002642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-05-09</td>\n",
       "      <td>[nhtsa, join, ntsb, look, fatal, tesla, crash,...</td>\n",
       "      <td>306.850006</td>\n",
       "      <td>0.016161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-04-12</td>\n",
       "      <td>[tesla, investig, feud, over, crash, tesla, in...</td>\n",
       "      <td>294.079987</td>\n",
       "      <td>-0.022763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>[tesla, halt, model, product, again, wall, str...</td>\n",
       "      <td>291.209991</td>\n",
       "      <td>-0.030399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-06-29</td>\n",
       "      <td>[elon, musk, tweet, featur, tesla, pickup, tru...</td>\n",
       "      <td>342.950012</td>\n",
       "      <td>-0.019947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-03-27</td>\n",
       "      <td>[tesla, defend, autopilot, record, fed, launch...</td>\n",
       "      <td>279.179993</td>\n",
       "      <td>-0.082188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-03-29</td>\n",
       "      <td>[tesla, recal, model, car, over, bolt, issu, w...</td>\n",
       "      <td>266.130005</td>\n",
       "      <td>0.032392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-04-26</td>\n",
       "      <td>[kany, cant, save, tesla, from, chipotl, long,...</td>\n",
       "      <td>285.480011</td>\n",
       "      <td>0.017065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-06-11</td>\n",
       "      <td>[buri, musk, cut, memo, home, depot, solar, sa...</td>\n",
       "      <td>332.100006</td>\n",
       "      <td>0.045457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018-07-11</td>\n",
       "      <td>[panason, say, open, work, with, tesla, china,...</td>\n",
       "      <td>318.959991</td>\n",
       "      <td>-0.010885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018-06-22</td>\n",
       "      <td>[tesla, crackup, foretold, real, problem, gove...</td>\n",
       "      <td>333.630005</td>\n",
       "      <td>-0.039941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018-05-15</td>\n",
       "      <td>[tesla, lose, energi, leader, musk, reorgan, b...</td>\n",
       "      <td>284.179993</td>\n",
       "      <td>-0.026681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018-07-05</td>\n",
       "      <td>[musk, say, norwegian, right, upset, with, tes...</td>\n",
       "      <td>309.160004</td>\n",
       "      <td>-0.005469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018-06-12</td>\n",
       "      <td>[tesla, deepak, ahuja, worst, tesla, layoff, t...</td>\n",
       "      <td>342.769989</td>\n",
       "      <td>0.032129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018-01-26</td>\n",
       "      <td>[tesla, superfan, stage, cancer, get, surpris,...</td>\n",
       "      <td>342.850006</td>\n",
       "      <td>0.015431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2018-01-22</td>\n",
       "      <td>[elon, musk, tesla, propos, could, earn, billi...</td>\n",
       "      <td>351.559998</td>\n",
       "      <td>0.004400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>[tesla, model, product, snarl, wall, street, w...</td>\n",
       "      <td>317.250000</td>\n",
       "      <td>-0.010233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2018-05-02</td>\n",
       "      <td>[tesla, rais, mani, question, just, make, sure...</td>\n",
       "      <td>301.149994</td>\n",
       "      <td>0.004101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2018-03-27</td>\n",
       "      <td>[tesla, go, come, roar, back, silicon, valley,...</td>\n",
       "      <td>279.179993</td>\n",
       "      <td>-0.082188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2018-04-04</td>\n",
       "      <td>[thi, polic, depart, switch, tesla, suv, elon,...</td>\n",
       "      <td>286.940002</td>\n",
       "      <td>0.072553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2018-04-03</td>\n",
       "      <td>[tesla, china, trade, elon, musk, thorniest, t...</td>\n",
       "      <td>267.529999</td>\n",
       "      <td>0.059609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2018-01-22</td>\n",
       "      <td>[tesla, chang, elon, musk, market, target, 10y...</td>\n",
       "      <td>351.559998</td>\n",
       "      <td>0.004400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>[tesla, deliv, model, sedan, total, vehicl, fo...</td>\n",
       "      <td>317.250000</td>\n",
       "      <td>-0.010233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2018-03-28</td>\n",
       "      <td>[elon, musk, might, control, tesla, bloomberg,...</td>\n",
       "      <td>257.779999</td>\n",
       "      <td>-0.076653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2018-03-15</td>\n",
       "      <td>[tesla, face, crunch, cash, hoard, thin, tesla...</td>\n",
       "      <td>325.600006</td>\n",
       "      <td>-0.003153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2018-05-21</td>\n",
       "      <td>[elon, musk, say, make, cheaper, model, would,...</td>\n",
       "      <td>284.489990</td>\n",
       "      <td>0.027707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2018-02-06</td>\n",
       "      <td>[tesla, earn, what, watch, tesla, expect, rele...</td>\n",
       "      <td>333.970001</td>\n",
       "      <td>0.002522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>[china, doe, tesla, favor, carmak, exist, join...</td>\n",
       "      <td>291.209991</td>\n",
       "      <td>-0.030399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1759</th>\n",
       "      <td>2018-03-07</td>\n",
       "      <td>[iran, industri, still, wait, cash, infusionen...</td>\n",
       "      <td>332.299988</td>\n",
       "      <td>0.012492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1760</th>\n",
       "      <td>2018-03-06</td>\n",
       "      <td>[magnesium, save, town, asbesto, centuri, mine...</td>\n",
       "      <td>328.200012</td>\n",
       "      <td>-0.015449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1761</th>\n",
       "      <td>2018-03-29</td>\n",
       "      <td>[russia, lash, back, john, bolton, polit, trum...</td>\n",
       "      <td>266.130005</td>\n",
       "      <td>0.032392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>2018-03-12</td>\n",
       "      <td>[robot, ride, go, deliv, pizza, parcel, befor,...</td>\n",
       "      <td>345.510010</td>\n",
       "      <td>0.056056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>[user, guid, driverless, car, wait, selfdriv, ...</td>\n",
       "      <td>316.579987</td>\n",
       "      <td>0.006230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1768</th>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>[real, time, econom, trade, tension, escal, ag...</td>\n",
       "      <td>291.209991</td>\n",
       "      <td>-0.030399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1769</th>\n",
       "      <td>2018-04-26</td>\n",
       "      <td>[million, year, partner, bid, grow, toptier, f...</td>\n",
       "      <td>285.480011</td>\n",
       "      <td>0.017065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1770</th>\n",
       "      <td>2018-04-11</td>\n",
       "      <td>[ryan, replac, pompeo, hill, senat, shield, mu...</td>\n",
       "      <td>300.929993</td>\n",
       "      <td>-0.012373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>[capit, journal, superpow, conflict, clinton, ...</td>\n",
       "      <td>291.209991</td>\n",
       "      <td>-0.030399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>2018-05-14</td>\n",
       "      <td>[which, motorcycl, should, guid, bike, there, ...</td>\n",
       "      <td>291.970001</td>\n",
       "      <td>-0.030193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>2018-07-26</td>\n",
       "      <td>[about, social, media, contagion, faang, take,...</td>\n",
       "      <td>306.649994</td>\n",
       "      <td>-0.006769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>2018-02-13</td>\n",
       "      <td>[product, februari, here, boost, dont, surrend...</td>\n",
       "      <td>323.660004</td>\n",
       "      <td>0.025116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>2018-04-03</td>\n",
       "      <td>[mueller, mandat, trump, unbound, china, tarif...</td>\n",
       "      <td>267.529999</td>\n",
       "      <td>0.059609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1778</th>\n",
       "      <td>2018-04-04</td>\n",
       "      <td>[real, time, econom, uschina, showdown, job, p...</td>\n",
       "      <td>286.940002</td>\n",
       "      <td>0.072553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>2018-02-08</td>\n",
       "      <td>[hous, pass, bill, shutdown, after, rand, paul...</td>\n",
       "      <td>315.230011</td>\n",
       "      <td>-0.086290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>2018-02-08</td>\n",
       "      <td>[hous, pass, bill, shutdown, after, rand, paul...</td>\n",
       "      <td>315.230011</td>\n",
       "      <td>-0.086290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>2018-06-21</td>\n",
       "      <td>[cant, hide, corpor, cop, also, data, scienc, ...</td>\n",
       "      <td>347.510010</td>\n",
       "      <td>-0.040611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1782</th>\n",
       "      <td>2018-07-25</td>\n",
       "      <td>[spacex, secret, weapon, gwynn, shotwel, launc...</td>\n",
       "      <td>308.739990</td>\n",
       "      <td>0.038026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783</th>\n",
       "      <td>2018-03-26</td>\n",
       "      <td>[facebook, help, shadi, advertis, pollut, inte...</td>\n",
       "      <td>304.179993</td>\n",
       "      <td>0.008755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1784</th>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>[cyberinsid, trade, illeg, bloomberg, hack, co...</td>\n",
       "      <td>349.250000</td>\n",
       "      <td>-0.014281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>2018-05-14</td>\n",
       "      <td>[gunlaw, loophol, that, entic, tycoon, crimin,...</td>\n",
       "      <td>291.970001</td>\n",
       "      <td>-0.030193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1787</th>\n",
       "      <td>2018-07-05</td>\n",
       "      <td>[walmart, take, stand, gun, right, peopl, like...</td>\n",
       "      <td>309.160004</td>\n",
       "      <td>-0.005469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1788</th>\n",
       "      <td>2018-05-24</td>\n",
       "      <td>[mike, meru, million, student, loan, that, hap...</td>\n",
       "      <td>277.850006</td>\n",
       "      <td>-0.004372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>2018-05-16</td>\n",
       "      <td>[tri, write, thi, stori, then, gave, wrote, da...</td>\n",
       "      <td>286.480011</td>\n",
       "      <td>0.008094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>2018-02-07</td>\n",
       "      <td>[china, outlook, seem, darkest, from, distanc,...</td>\n",
       "      <td>345.000000</td>\n",
       "      <td>0.033027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791</th>\n",
       "      <td>2018-02-06</td>\n",
       "      <td>[comstock, challeng, trump, over, shutdown, co...</td>\n",
       "      <td>333.970001</td>\n",
       "      <td>0.002522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>2018-04-09</td>\n",
       "      <td>[instagram, look, like, facebook, best, hope, ...</td>\n",
       "      <td>289.660004</td>\n",
       "      <td>-0.032208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>2018-04-23</td>\n",
       "      <td>[cnbc, excerpt, cnbc, broadcast, live, sohn, i...</td>\n",
       "      <td>283.369995</td>\n",
       "      <td>-0.023670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>2018-05-23</td>\n",
       "      <td>[china, 36thbest, compani, save, volvo, bloomb...</td>\n",
       "      <td>279.070007</td>\n",
       "      <td>0.014763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>2018-05-16</td>\n",
       "      <td>[appl, rival, their, futur, these, men, dream,...</td>\n",
       "      <td>286.480011</td>\n",
       "      <td>0.008094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1227 rows Ã 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Published                                               Text  \\\n",
       "0    2018-04-02  [tesla, end, make, model, sedan, week, tesla, ...   \n",
       "1    2018-07-23  [tesla, want, money, back, elon, musk, ask, do...   \n",
       "3    2018-05-08  [florida, teenag, kill, tesla, crash, tesla, s...   \n",
       "4    2018-05-09  [nhtsa, join, ntsb, look, fatal, tesla, crash,...   \n",
       "5    2018-04-12  [tesla, investig, feud, over, crash, tesla, in...   \n",
       "6    2018-04-16  [tesla, halt, model, product, again, wall, str...   \n",
       "7    2018-06-29  [elon, musk, tweet, featur, tesla, pickup, tru...   \n",
       "8    2018-03-27  [tesla, defend, autopilot, record, fed, launch...   \n",
       "9    2018-03-29  [tesla, recal, model, car, over, bolt, issu, w...   \n",
       "10   2018-04-26  [kany, cant, save, tesla, from, chipotl, long,...   \n",
       "11   2018-06-11  [buri, musk, cut, memo, home, depot, solar, sa...   \n",
       "13   2018-07-11  [panason, say, open, work, with, tesla, china,...   \n",
       "16   2018-06-22  [tesla, crackup, foretold, real, problem, gove...   \n",
       "17   2018-05-15  [tesla, lose, energi, leader, musk, reorgan, b...   \n",
       "18   2018-07-05  [musk, say, norwegian, right, upset, with, tes...   \n",
       "19   2018-06-12  [tesla, deepak, ahuja, worst, tesla, layoff, t...   \n",
       "20   2018-01-26  [tesla, superfan, stage, cancer, get, surpris,...   \n",
       "21   2018-01-22  [elon, musk, tesla, propos, could, earn, billi...   \n",
       "22   2018-01-03  [tesla, model, product, snarl, wall, street, w...   \n",
       "23   2018-05-02  [tesla, rais, mani, question, just, make, sure...   \n",
       "24   2018-03-27  [tesla, go, come, roar, back, silicon, valley,...   \n",
       "26   2018-04-04  [thi, polic, depart, switch, tesla, suv, elon,...   \n",
       "27   2018-04-03  [tesla, china, trade, elon, musk, thorniest, t...   \n",
       "28   2018-01-22  [tesla, chang, elon, musk, market, target, 10y...   \n",
       "29   2018-01-03  [tesla, deliv, model, sedan, total, vehicl, fo...   \n",
       "30   2018-03-28  [elon, musk, might, control, tesla, bloomberg,...   \n",
       "31   2018-03-15  [tesla, face, crunch, cash, hoard, thin, tesla...   \n",
       "32   2018-05-21  [elon, musk, say, make, cheaper, model, would,...   \n",
       "35   2018-02-06  [tesla, earn, what, watch, tesla, expect, rele...   \n",
       "36   2018-04-16  [china, doe, tesla, favor, carmak, exist, join...   \n",
       "...         ...                                                ...   \n",
       "1759 2018-03-07  [iran, industri, still, wait, cash, infusionen...   \n",
       "1760 2018-03-06  [magnesium, save, town, asbesto, centuri, mine...   \n",
       "1761 2018-03-29  [russia, lash, back, john, bolton, polit, trum...   \n",
       "1762 2018-03-12  [robot, ride, go, deliv, pizza, parcel, befor,...   \n",
       "1767 2018-01-05  [user, guid, driverless, car, wait, selfdriv, ...   \n",
       "1768 2018-04-16  [real, time, econom, trade, tension, escal, ag...   \n",
       "1769 2018-04-26  [million, year, partner, bid, grow, toptier, f...   \n",
       "1770 2018-04-11  [ryan, replac, pompeo, hill, senat, shield, mu...   \n",
       "1771 2018-04-16  [capit, journal, superpow, conflict, clinton, ...   \n",
       "1773 2018-05-14  [which, motorcycl, should, guid, bike, there, ...   \n",
       "1774 2018-07-26  [about, social, media, contagion, faang, take,...   \n",
       "1776 2018-02-13  [product, februari, here, boost, dont, surrend...   \n",
       "1777 2018-04-03  [mueller, mandat, trump, unbound, china, tarif...   \n",
       "1778 2018-04-04  [real, time, econom, uschina, showdown, job, p...   \n",
       "1779 2018-02-08  [hous, pass, bill, shutdown, after, rand, paul...   \n",
       "1780 2018-02-08  [hous, pass, bill, shutdown, after, rand, paul...   \n",
       "1781 2018-06-21  [cant, hide, corpor, cop, also, data, scienc, ...   \n",
       "1782 2018-07-25  [spacex, secret, weapon, gwynn, shotwel, launc...   \n",
       "1783 2018-03-26  [facebook, help, shadi, advertis, pollut, inte...   \n",
       "1784 2018-02-01  [cyberinsid, trade, illeg, bloomberg, hack, co...   \n",
       "1786 2018-05-14  [gunlaw, loophol, that, entic, tycoon, crimin,...   \n",
       "1787 2018-07-05  [walmart, take, stand, gun, right, peopl, like...   \n",
       "1788 2018-05-24  [mike, meru, million, student, loan, that, hap...   \n",
       "1789 2018-05-16  [tri, write, thi, stori, then, gave, wrote, da...   \n",
       "1790 2018-02-07  [china, outlook, seem, darkest, from, distanc,...   \n",
       "1791 2018-02-06  [comstock, challeng, trump, over, shutdown, co...   \n",
       "1793 2018-04-09  [instagram, look, like, facebook, best, hope, ...   \n",
       "1794 2018-04-23  [cnbc, excerpt, cnbc, broadcast, live, sohn, i...   \n",
       "1795 2018-05-23  [china, 36thbest, compani, save, volvo, bloomb...   \n",
       "1796 2018-05-16  [appl, rival, their, futur, these, men, dream,...   \n",
       "\n",
       "       Adj Close    Return  \n",
       "0     252.479996 -0.051291  \n",
       "1     303.200012 -0.033102  \n",
       "3     301.970001 -0.002642  \n",
       "4     306.850006  0.016161  \n",
       "5     294.079987 -0.022763  \n",
       "6     291.209991 -0.030399  \n",
       "7     342.950012 -0.019947  \n",
       "8     279.179993 -0.082188  \n",
       "9     266.130005  0.032392  \n",
       "10    285.480011  0.017065  \n",
       "11    332.100006  0.045457  \n",
       "13    318.959991 -0.010885  \n",
       "16    333.630005 -0.039941  \n",
       "17    284.179993 -0.026681  \n",
       "18    309.160004 -0.005469  \n",
       "19    342.769989  0.032129  \n",
       "20    342.850006  0.015431  \n",
       "21    351.559998  0.004400  \n",
       "22    317.250000 -0.010233  \n",
       "23    301.149994  0.004101  \n",
       "24    279.179993 -0.082188  \n",
       "26    286.940002  0.072553  \n",
       "27    267.529999  0.059609  \n",
       "28    351.559998  0.004400  \n",
       "29    317.250000 -0.010233  \n",
       "30    257.779999 -0.076653  \n",
       "31    325.600006 -0.003153  \n",
       "32    284.489990  0.027707  \n",
       "35    333.970001  0.002522  \n",
       "36    291.209991 -0.030399  \n",
       "...          ...       ...  \n",
       "1759  332.299988  0.012492  \n",
       "1760  328.200012 -0.015449  \n",
       "1761  266.130005  0.032392  \n",
       "1762  345.510010  0.056056  \n",
       "1767  316.579987  0.006230  \n",
       "1768  291.209991 -0.030399  \n",
       "1769  285.480011  0.017065  \n",
       "1770  300.929993 -0.012373  \n",
       "1771  291.209991 -0.030399  \n",
       "1773  291.970001 -0.030193  \n",
       "1774  306.649994 -0.006769  \n",
       "1776  323.660004  0.025116  \n",
       "1777  267.529999  0.059609  \n",
       "1778  286.940002  0.072553  \n",
       "1779  315.230011 -0.086290  \n",
       "1780  315.230011 -0.086290  \n",
       "1781  347.510010 -0.040611  \n",
       "1782  308.739990  0.038026  \n",
       "1783  304.179993  0.008755  \n",
       "1784  349.250000 -0.014281  \n",
       "1786  291.970001 -0.030193  \n",
       "1787  309.160004 -0.005469  \n",
       "1788  277.850006 -0.004372  \n",
       "1789  286.480011  0.008094  \n",
       "1790  345.000000  0.033027  \n",
       "1791  333.970001  0.002522  \n",
       "1793  289.660004 -0.032208  \n",
       "1794  283.369995 -0.023670  \n",
       "1795  279.070007  0.014763  \n",
       "1796  286.480011  0.008094  \n",
       "\n",
       "[1227 rows x 4 columns]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

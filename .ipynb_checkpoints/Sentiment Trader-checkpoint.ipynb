{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#author: James Chan Â© 2018\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import st_utils as ut\n",
    "import trader_utils as tu\n",
    "import string\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "\n",
    "from dateutil import parser\n",
    "from datetime import timedelta, date\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize date range\n",
    "start_date = '2018-01-01'\n",
    "end_date = '2018-8-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'ok', 'totalResults': 1875, 'articles': []}\n",
      "total number of articles  1875\n",
      "downloading page:  1\n",
      "downloading page:  2\n",
      "downloading page:  3\n",
      "downloading page:  4\n",
      "downloading page:  5\n",
      "downloading page:  6\n",
      "downloading page:  7\n",
      "downloading page:  8\n",
      "downloading page:  9\n",
      "downloading page:  10\n",
      "downloading page:  11\n",
      "downloading page:  12\n",
      "downloading page:  13\n",
      "downloading page:  14\n",
      "downloading page:  15\n",
      "downloading page:  16\n",
      "downloading page:  17\n",
      "downloading page:  18\n",
      "downloading page:  19\n",
      "download complete\n"
     ]
    }
   ],
   "source": [
    "# grab news.  nnly need to do this once\n",
    "keywords = ['tesla'] #these three stocks move largely base on news\n",
    "news_source = 'wsj.com, bloomberg.com, cnbc.com'\n",
    "df = ut.get_news(keywords, start_date, end_date, news_source)\n",
    "df.to_csv('news_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>320.529999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>317.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>314.619995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>316.579987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08</th>\n",
       "      <td>336.410004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Adj Close\n",
       "2018-01-02  320.529999\n",
       "2018-01-03  317.250000\n",
       "2018-01-04  314.619995\n",
       "2018-01-05  316.579987\n",
       "2018-01-08  336.410004"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get Tesla's prices\n",
    "dates = pd.date_range(start_date, end_date)\n",
    "file = 'TSLA.csv'\n",
    "df_stock = ut.get_data(file, dates)\n",
    "df_stock.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate return \n",
    "df_stock['Return'] = df_stock['Adj Close'].pct_change()\n",
    "df_stock.drop(df_stock.index[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Published</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-04-03T13:05:17Z</td>\n",
       "      <td>Tesla Ends 1Q Making 2,020 Model 3 Sedans per ...</td>\n",
       "      <td>Tesla 1Q deliveries totaled 29,980 vehicles, B...</td>\n",
       "      <td>tesla</td>\n",
       "      <td>Bloomberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-07-24T07:48:09Z</td>\n",
       "      <td>Tesla Wants Its Money Back</td>\n",
       "      <td>Elon Musk is asking for donations to save Tesl...</td>\n",
       "      <td>tesla</td>\n",
       "      <td>The Wall Street Journal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-07-01T22:13:00Z</td>\n",
       "      <td>What Tesla can do to keep the bears at bay dur...</td>\n",
       "      <td>Buckle up, because Tesla could be in for a bum...</td>\n",
       "      <td>tesla</td>\n",
       "      <td>CNBC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-05-09T15:00:00Z</td>\n",
       "      <td>Two Florida teenagers killed in Tesla crash</td>\n",
       "      <td>Tesla said it is cooperating with authorities ...</td>\n",
       "      <td>tesla</td>\n",
       "      <td>CNBC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-05-10T19:00:00Z</td>\n",
       "      <td>NHTSA joins NTSB in looking into fatal Tesla c...</td>\n",
       "      <td>Tesla said it is cooperating with authorities ...</td>\n",
       "      <td>tesla</td>\n",
       "      <td>CNBC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Published                                              Title  \\\n",
       "0  2018-04-03T13:05:17Z  Tesla Ends 1Q Making 2,020 Model 3 Sedans per ...   \n",
       "1  2018-07-24T07:48:09Z                         Tesla Wants Its Money Back   \n",
       "2  2018-07-01T22:13:00Z  What Tesla can do to keep the bears at bay dur...   \n",
       "3  2018-05-09T15:00:00Z        Two Florida teenagers killed in Tesla crash   \n",
       "4  2018-05-10T19:00:00Z  NHTSA joins NTSB in looking into fatal Tesla c...   \n",
       "\n",
       "                                                Body Keyword  \\\n",
       "0  Tesla 1Q deliveries totaled 29,980 vehicles, B...   tesla   \n",
       "1  Elon Musk is asking for donations to save Tesl...   tesla   \n",
       "2  Buckle up, because Tesla could be in for a bum...   tesla   \n",
       "3  Tesla said it is cooperating with authorities ...   tesla   \n",
       "4  Tesla said it is cooperating with authorities ...   tesla   \n",
       "\n",
       "                    Source  \n",
       "0                Bloomberg  \n",
       "1  The Wall Street Journal  \n",
       "2                     CNBC  \n",
       "3                     CNBC  \n",
       "4                     CNBC  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news = pd.read_csv('news_dataset.csv', index_col=0, encoding=\"ISO-8859-1\")\n",
    "df_news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# map published time to close date.  see figure.1\n",
    "def map_to_close_date(published_date):\n",
    "    dt = parser.parse(published_date[:-1]) #-1 to ignore the Z, which is GMT.\n",
    "    dt = dt - timedelta(hours=20) #shift back by 20 hrs.\n",
    "    return pd.Timestamp(year=dt.year, month=dt.month, day=dt.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# map news to close date\n",
    "df_news['Published'] = df_news['Published'].apply(map_to_close_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combine title and body into single text\n",
    "df_news['Text'] = df_news['Title'] + ' ' + df_news['Body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# just keep published, and the combined text\n",
    "df_news = df_news[['Published','Text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Published</th>\n",
       "      <th>Text</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-04-02</td>\n",
       "      <td>Tesla Ends 1Q Making 2,020 Model 3 Sedans per ...</td>\n",
       "      <td>252.479996</td>\n",
       "      <td>-0.051291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-07-23</td>\n",
       "      <td>Tesla Wants Its Money Back Elon Musk is asking...</td>\n",
       "      <td>303.200012</td>\n",
       "      <td>-0.033102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-05-08</td>\n",
       "      <td>Two Florida teenagers killed in Tesla crash Te...</td>\n",
       "      <td>301.970001</td>\n",
       "      <td>-0.002642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-05-09</td>\n",
       "      <td>NHTSA joins NTSB in looking into fatal Tesla c...</td>\n",
       "      <td>306.850006</td>\n",
       "      <td>0.016161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-04-12</td>\n",
       "      <td>Tesla, Investigators Feud Over a Crash Tesla, ...</td>\n",
       "      <td>294.079987</td>\n",
       "      <td>-0.022763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Published                                               Text   Adj Close  \\\n",
       "0 2018-04-02  Tesla Ends 1Q Making 2,020 Model 3 Sedans per ...  252.479996   \n",
       "1 2018-07-23  Tesla Wants Its Money Back Elon Musk is asking...  303.200012   \n",
       "3 2018-05-08  Two Florida teenagers killed in Tesla crash Te...  301.970001   \n",
       "4 2018-05-09  NHTSA joins NTSB in looking into fatal Tesla c...  306.850006   \n",
       "5 2018-04-12  Tesla, Investigators Feud Over a Crash Tesla, ...  294.079987   \n",
       "\n",
       "     Return  \n",
       "0 -0.051291  \n",
       "1 -0.033102  \n",
       "3 -0.002642  \n",
       "4  0.016161  \n",
       "5 -0.022763  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge news and stock\n",
    "df_stock['Published'] = df_stock.index\n",
    "df_merged = pd.merge(df_news, df_stock, how='left', on='Published')\n",
    "df_merged = df_merged.dropna()\n",
    "df_merged.sort_values(by='Published')\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_news(text):\n",
    "    if(type(text)==float):\n",
    "        return []\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    stmr = PorterStemmer()\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    text = (text.translate(translator))\n",
    "    text = \"\".join(c for c in text if ord(c)<128) #strip no n ascii characters\n",
    "    tokens = nltk.tokenize.word_tokenize(text)\n",
    "    t = []\n",
    "    minlen =  4\n",
    "    maxlen = 20 \n",
    "    for token in tokens:\n",
    "        if len(token) < minlen or len(token) > maxlen or token.isnumeric() or token in stopwords.words('english'):\n",
    "            pass\n",
    "        else:\n",
    "            token = lmtzr.lemmatize(token)\n",
    "            token = stmr.stem(token)\n",
    "            t.append(token)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_merged['Text'] = df_merged['Text'].apply(tokenize_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Published</th>\n",
       "      <th>Text</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-04-02</td>\n",
       "      <td>[tesla, end, make, model, sedan, week, tesla, ...</td>\n",
       "      <td>252.479996</td>\n",
       "      <td>-0.051291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-07-23</td>\n",
       "      <td>[tesla, want, money, back, elon, musk, ask, do...</td>\n",
       "      <td>303.200012</td>\n",
       "      <td>-0.033102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-05-08</td>\n",
       "      <td>[florida, teenag, kill, tesla, crash, tesla, s...</td>\n",
       "      <td>301.970001</td>\n",
       "      <td>-0.002642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-05-09</td>\n",
       "      <td>[nhtsa, join, ntsb, look, fatal, tesla, crash,...</td>\n",
       "      <td>306.850006</td>\n",
       "      <td>0.016161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-04-12</td>\n",
       "      <td>[tesla, investig, feud, over, crash, tesla, in...</td>\n",
       "      <td>294.079987</td>\n",
       "      <td>-0.022763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Published                                               Text   Adj Close  \\\n",
       "0 2018-04-02  [tesla, end, make, model, sedan, week, tesla, ...  252.479996   \n",
       "1 2018-07-23  [tesla, want, money, back, elon, musk, ask, do...  303.200012   \n",
       "3 2018-05-08  [florida, teenag, kill, tesla, crash, tesla, s...  301.970001   \n",
       "4 2018-05-09  [nhtsa, join, ntsb, look, fatal, tesla, crash,...  306.850006   \n",
       "5 2018-04-12  [tesla, investig, feud, over, crash, tesla, in...  294.079987   \n",
       "\n",
       "     Return  \n",
       "0 -0.051291  \n",
       "1 -0.033102  \n",
       "3 -0.002642  \n",
       "4  0.016161  \n",
       "5 -0.022763  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#construct vocabulary and frequency.  frequency is not really needed, just nice to have for understanding the concept.\n",
    "vocab = {}\n",
    "frequency = {}\n",
    "ignore = ['bloomberg', 'journal']\n",
    "index = 0\n",
    "for title in df_merged['Text']:\n",
    "    for word in title:\n",
    "        if word in ignore:\n",
    "            continue\n",
    "        if word not in vocab:\n",
    "            vocab[word] = index\n",
    "            index += 1\n",
    "            frequency[word] = 1\n",
    "        else:\n",
    "            frequency[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('tesla', 1097)\n",
      "('musk', 461)\n",
      "('elon', 366)\n",
      "('compani', 249)\n",
      "('stock', 246)\n",
      "('model', 241)\n",
      "('say', 182)\n",
      "('china', 160)\n",
      "('share', 159)\n",
      "('market', 159)\n"
     ]
    }
   ],
   "source": [
    "#visualize words frequency\n",
    "for i, freq in enumerate(sorted(frequency.items(), key=lambda x:x[1], reverse=True)):\n",
    "    if i == 10:\n",
    "        break\n",
    "    print(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_len = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_one_hot(text):\n",
    "    #return one hot vector of shape (vocab_len, 1)\n",
    "    array = np.zeros((vocab_len, 1))\n",
    "    for word in text:\n",
    "        if word in vocab:\n",
    "            index = vocab[word]\n",
    "            array[index] = 1\n",
    "    return array\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# here is the exciting part. here we are going to create the training data!\n",
    "X = np.empty((vocab_len,0))\n",
    "for text in df_merged['Text']:\n",
    "    array = to_one_hot(text)\n",
    "    X = np.hstack((X,array))\n",
    "X = X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get labels\n",
    "Y = df_merged['Return'].values.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "negative_idx = (Y <= 0)\n",
    "positive_idx = (Y > 0)\n",
    "Y[negative_idx] = 0\n",
    "Y[positive_idx] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Feature Size (num_examples X vocab_size):  (1228, 4534)\n",
      "Label Size (num_examples):  (1228,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Input Feature Size (num_examples X vocab_size): \",X.shape)\n",
    "print(\"Label Size (num_examples): \", Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1105, 4534)\n",
      "(123, 4534)\n",
      "(1105,)\n",
      "(123,)\n"
     ]
    }
   ],
   "source": [
    "#train test split\n",
    "train_size = .9\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b3c2409a20>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=X_train.shape[1], activation='relu', kernel_initializer='uniform'))\n",
    "# model.add(Dense(12, activation='relu', kernel_initializer='uniform'))\n",
    "# model.add(Dense(1, activation='sigmoid', kernel_initializer='uniform'))\n",
    "\n",
    "optimizer = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.00001, amsgrad=False)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, epochs=50, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tesla [0.02952633]\n",
      "end [-0.24720483]\n",
      "make [0.03284777]\n",
      "model [0.01605833]\n",
      "sedan [0.04877686]\n",
      "week [0.00196528]\n",
      "deliveri [-0.03385526]\n",
      "total [0.08856238]\n",
      "vehicl [0.05465103]\n",
      "new [0.02539405]\n"
     ]
    }
   ],
   "source": [
    "#view weights\n",
    "weights, biases = model.layers[0].get_weights()\n",
    "for i, k in enumerate(vocab.keys()):\n",
    "    if i == 10:\n",
    "        break\n",
    "    print(k, weights[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9683257918552036"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#assess in-sample accuracy\n",
    "predictions = model.predict_classes(X_train)\n",
    "predictions = predictions.reshape((predictions.shape[0],))\n",
    "np.sum(predictions == Y_train) / Y_train.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5284552845528455"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#assess out-of-sample accuracy\n",
    "predictions = model.predict_classes(X_test)\n",
    "predictions = predictions.reshape((predictions.shape[0],))\n",
    "np.sum(predictions == Y_test) / Y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
